{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c0f6d04",
   "metadata": {},
   "source": [
    "## Neural Network [NN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "489d8542",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, max_error\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.linear_model import LassoCV\n",
    "from torch.utils.data import random_split\n",
    "from collections import OrderedDict\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix,classification_report\n",
    "%config Completer.use_jedi = False\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58df887f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the dataset\n",
    "qsar = pd.read_csv('biodeg.csv', sep = ';')\n",
    "qsar = qsar.drop(\"Unnamed: 42\", axis=1) # removing the unnamed column if it exist when the .csv file is read\n",
    "#qsar.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa1f9205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='experimental_class', ylabel='count'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEHCAYAAABBW1qbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAVU0lEQVR4nO3de5Qed33f8fcHGV8AE6xaNkKykUJUEpkEA4sCgcMhiGLnUuRSHETrViTOUdLjphACqZ1SICRKHC5NCMUNSggWheCoBNeCngPoiLiE4liW8VW2VQtMbEXCEiaUmxGR+PaP57fD49Wu/CA0u+vd9+ucPTPzm9/MfLVe72dn5pnfpKqQJAngUTNdgCRp9jAUJEkdQ0GS1DEUJEkdQ0GS1Dlhpgv4QZx++um1bNmymS5Dkh5Rbrzxxi9X1aLJ1j2iQ2HZsmXs2LFjpsuQpEeUJH831TovH0mSOoaCJKljKEiSOoaCJKljKEiSOr2FQpKnJrl56OtrSV6TZGGSrUnubtPThra5LMnuJLuSnNdXbZKkyfUWClW1q6rOrapzgWcB3wKuBi4FtlXVCmBbWybJSmAtcA5wPnBFkgV91SdJOtJ0XT5aDXy+qv4OWANsau2bgAva/Brgqqo6WFX3ALuBVdNUnySJ6QuFtcCH2vyZVbUPoE3PaO1LgPuGttnT2iRJ06T3J5qTnAi8FLjs4bpO0nbEG4CSrAfWA5x99tk/cH3SbHXvW358pkvQLHT2G2/rdf/TcabwM8Dnqur+tnx/ksUAbbq/te8Bzhrabimwd+LOqmpjVY1V1diiRZMO3SFJOkbTEQqv5HuXjgC2AOva/DrgmqH2tUlOSrIcWAFsn4b6JElNr5ePkjwG+GfArww1Xw5sTnIxcC9wIUBV7UyyGbgDOARcUlWH+6xPkvRQvYZCVX0L+CcT2h5g8GmkyfpvADb0WZMkaWo+0SxJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6vQaCkmekOTDSe5KcmeS5yZZmGRrkrvb9LSh/pcl2Z1kV5Lz+qxNknSkvs8U3gl8vKp+FHg6cCdwKbCtqlYA29oySVYCa4FzgPOBK5Is6Lk+SdKQ3kIhyeOBFwDvBaiq71TVV4E1wKbWbRNwQZtfA1xVVQer6h5gN7Cqr/okSUfq80zhh4EDwPuS3JTkz5I8FjizqvYBtOkZrf8S4L6h7fe0todIsj7JjiQ7Dhw40GP5kjT/9BkKJwDPBP5bVT0D+CbtUtEUMklbHdFQtbGqxqpqbNGiRcenUkkS0G8o7AH2VNX1bfnDDELi/iSLAdp0/1D/s4a2Xwrs7bE+SdIEvYVCVX0JuC/JU1vTauAOYAuwrrWtA65p81uAtUlOSrIcWAFs76s+SdKRTuh5/78GfDDJicAXgF9kEESbk1wM3AtcCFBVO5NsZhAch4BLqupwz/VJkob0GgpVdTMwNsmq1VP03wBs6LMmSdLUfKJZktQxFCRJHUNBktQxFCRJHUNBktQxFCRJHUNBktQxFCRJHUNBktQxFCRJHUNBktQxFCRJHUNBktQxFCRJHUNBktQxFCRJHUNBktQxFCRJHUNBktQxFCRJHUNBktTpNRSSfDHJbUluTrKjtS1MsjXJ3W162lD/y5LsTrIryXl91iZJOtJ0nCn8dFWdW1VjbflSYFtVrQC2tWWSrATWAucA5wNXJFkwDfVJkpqZuHy0BtjU5jcBFwy1X1VVB6vqHmA3sGr6y5Ok+avvUCjgk0luTLK+tZ1ZVfsA2vSM1r4EuG9o2z2t7SGSrE+yI8mOAwcO9Fi6JM0/J/S8/+dV1d4kZwBbk9x1lL6ZpK2OaKjaCGwEGBsbO2K9JOnY9XqmUFV723Q/cDWDy0H3J1kM0Kb7W/c9wFlDmy8F9vZZnyTpoXoLhSSPTXLq+DzwEuB2YAuwrnVbB1zT5rcAa5OclGQ5sALY3ld9kqQj9Xn56Ezg6iTjx/mLqvp4khuAzUkuBu4FLgSoqp1JNgN3AIeAS6rqcI/1SZIm6C0UquoLwNMnaX8AWD3FNhuADX3VJEk6Op9oliR1DAVJUsdQkCR1DAVJUsdQkCR1DAVJUsdQkCR1DAVJUsdQkCR1DAVJUsdQkCR1DAVJUsdQkCR1DAVJUsdQkCR1DAVJUsdQkCR1DAVJUsdQkCR1DAVJUqf3UEiyIMlNST7Wlhcm2Zrk7jY9bajvZUl2J9mV5Ly+a5MkPdR0nCm8GrhzaPlSYFtVrQC2tWWSrATWAucA5wNXJFkwDfVJkpqRQiHJtlHaJumzFPg54M+GmtcAm9r8JuCCofarqupgVd0D7AZWjVKfJOn4OOFoK5OcDDwGOL1d5klb9XjgSSPs/4+A3wROHWo7s6r2AVTVviRntPYlwN8O9dvT2ibWtB5YD3D22WePUIIkaVQPd6bwK8CNwI+26fjXNcC7j7Zhkp8H9lfVjSPWkkna6oiGqo1VNVZVY4sWLRpx15KkURz1TKGq3gm8M8mvVdW7vs99Pw94aZKfBU4GHp/kA8D9SRa3s4TFwP7Wfw9w1tD2S4G93+cxJUk/gJHuKVTVu5L8VJJ/leTfjn89zDaXVdXSqlrG4Abyp6rqImALsK51W8fgrIPWvjbJSUmWAyuA7cfwb5IkHaOjnimMS/LfgacANwOHW3MB7z+GY14ObE5yMXAvcCFAVe1Mshm4AzgEXFJVh6fejSTpeBspFIAxYGVVHXGNfxRVdS1wbZt/AFg9Rb8NwIZjOYYk6Qc36nMKtwNP7LMQSdLMG/VM4XTgjiTbgYPjjVX10l6qkiTNiFFD4c19FiFJmh1GCoWq+t99FyJJmnmjfvro63zvQbITgUcD36yqx/dVmCRp+o16pjA8TAVJLsBxiSRpzjmmUVKr6n8CLzq+pUiSZtqol49eNrT4KAbPLRzTMwuzzbNefyzP32muu/FtR31gX5qzRv300T8fmj8EfJHBUNeSpDlk1HsKv9h3IZKkmTfqS3aWJrk6yf4k9yf5q/YCHUnSHDLqjeb3MRjF9EkMXnzz0dYmSZpDRg2FRVX1vqo61L6uBHzDjSTNMaOGwpeTXJRkQfu6CHigz8IkSdNv1FD4JeAXgC8B+4CXA958lqQ5ZtSPpP4OsK6q/gEgyULg7QzCQpI0R4x6pvAT44EAUFVfAZ7RT0mSpJkyaig8Kslp4wvtTGHUswxJ0iPEqL/Y3wF8NsmHGQxv8Qv42kxJmnNGfaL5/Ul2MBgEL8DLquqOXiuTJE27kS8BtRAwCCRpDjumobNHkeTkJNuT3JJkZ5Lfbu0Lk2xNcnebDt+ruCzJ7iS7kpzXV22SpMn1FgrAQeBFVfV04Fzg/CTPAS4FtlXVCmBbWybJSmAtcA5wPnBFkgU91idJmqC3UKiBb7TFR7evYjDk9qbWvgm4oM2vAa6qqoNVdQ+wG9/uJknTqs8zBdqQGDcD+4GtVXU9cGZV7QNo0zNa9yXAfUOb72ltE/e5PsmOJDsOHDjQZ/mSNO/0GgpVdbiqzgWWAquSPO0o3TPZLibZ58aqGquqsUWLHJNPko6nXkNhXFV9FbiWwb2C+5MsBmjT/a3bHuCsoc2WAnunoz5J0kCfnz5alOQJbf4U4MXAXQzey7CudVsHXNPmtwBrk5yUZDmwAtjeV32SpCP1OVTFYmBT+wTRo4DNVfWxJNcBm5NcDNwLXAhQVTuTbGbwLMQh4JKqOtxjfZKkCXoLhaq6lUkGzauqB4DVU2yzAYfPkKQZMy33FCRJjwyGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSp01soJDkryV8nuTPJziSvbu0Lk2xNcnebnja0zWVJdifZleS8vmqTJE2uzzOFQ8BvVNWPAc8BLkmyErgU2FZVK4BtbZm2bi1wDnA+cEWSBT3WJ0maoLdQqKp9VfW5Nv914E5gCbAG2NS6bQIuaPNrgKuq6mBV3QPsBlb1VZ8k6UjTck8hyTLgGcD1wJlVtQ8GwQGc0botAe4b2mxPa5MkTZPeQyHJ44C/Al5TVV87WtdJ2mqS/a1PsiPJjgMHDhyvMiVJ9BwKSR7NIBA+WFUfac33J1nc1i8G9rf2PcBZQ5svBfZO3GdVbayqsaoaW7RoUX/FS9I81OenjwK8F7izqv7L0KotwLo2vw64Zqh9bZKTkiwHVgDb+6pPknSkE3rc9/OAfwPcluTm1vZbwOXA5iQXA/cCFwJU1c4km4E7GHxy6ZKqOtxjfZKkCXoLhar6DJPfJwBYPcU2G4ANfdUkSTo6n2iWJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHV6C4Ukf55kf5Lbh9oWJtma5O42PW1o3WVJdifZleS8vuqSJE2tzzOFK4HzJ7RdCmyrqhXAtrZMkpXAWuCcts0VSRb0WJskaRK9hUJVfRr4yoTmNcCmNr8JuGCo/aqqOlhV9wC7gVV91SZJmtx031M4s6r2AbTpGa19CXDfUL89re0ISdYn2ZFkx4EDB3otVpLmm9lyozmTtNVkHatqY1WNVdXYokWLei5LkuaX6Q6F+5MsBmjT/a19D3DWUL+lwN5prk2S5r3pDoUtwLo2vw64Zqh9bZKTkiwHVgDbp7k2SZr3Tuhrx0k+BLwQOD3JHuBNwOXA5iQXA/cCFwJU1c4km4E7gEPAJVV1uK/aJEmT6y0UquqVU6xaPUX/DcCGvuqRJD282XKjWZI0CxgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6sy6UEhyfpJdSXYnuXSm65Gk+WRWhUKSBcC7gZ8BVgKvTLJyZquSpPljVoUCsArYXVVfqKrvAFcBa2a4JkmaN06Y6QImWALcN7S8B/jJ4Q5J1gPr2+I3kuyaptrmg9OBL890EbNB3r5upkvQQ/mzOe5NOR57efJUK2ZbKEz2r62HLFRtBDZOTznzS5IdVTU203VIE/mzOX1m2+WjPcBZQ8tLgb0zVIskzTuzLRRuAFYkWZ7kRGAtsGWGa5KkeWNWXT6qqkNJ/j3wCWAB8OdVtXOGy5pPvCyn2cqfzWmSqnr4XpKkeWG2XT6SJM0gQ0GS1DEU5qEkh5PcnOT2JB9N8oTWvizJg23dLUk+m+SpM1yu5rgkleQdQ8uvS/LmNv/mJH/ffibvSPLKoX5XJrmnrbsryZtmoPw5x1CYnx6sqnOr6mnAV4BLhtZ9vq17OrAJ+K0ZqVDzyUHgZUlOn2L9H1bVuQxGN3hPkkcPrXt9W3cusC7J8j4LnQ8MBV3H4EnyyTwe+IdprEXz0yEGny769aN1qqq7gW8Bp02y+uQ2/ebxLW3+mVUfSdX0agMQrgbeO9T8lCQ3A6cCj2HCMCNST94N3JrkrVN1SPJM4O6q2j/U/LYkbwB+BPjjCet0DDxTmJ9Oab/4HwAWAluH1o1fPnoK8Br8fLimQVV9DXg/8B8mWf3rbYyz64E3T1g3fvnoicDqJD/VZ53zgaEwPz3Y/kd6MnAiD72nMGwL8ILpKkrz3h8BFwOPndD+h1X1VOAVwPuTnDxxw6r6BnAt8Pyea5zzDIV5rKr+H4O/zF434ebduOcDn5/eqjRfVdVXgM0MgmGy9R8BdgBHDGGb5AQGlzr9ef0BGQrzXFXdBNzCYJwpaPcUktwC/B7wyzNWnOajdzAYJnsqbwFem2T8d9fb2qXQW4HbgI/0W97c5zAXkqSOZwqSpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnqGApSk+QtSV7c8zFeleRJI/S7MsnLv899vzDJx469OskB8SRgMDhgVb1xGg71KuB2YO80HEv6vnmmoFktyUVJtrenrN+T5CeT3Jrk5CSPTbIzydPaX8mfTnJ1exnLn4w/9ZrkJUmuS/K5JP8jyeNa+xeTvDHJZ4ALh/86b+t+r223I8kzk3wiyeeT/OpQfa9PckOr6bdb27Ikdyb501bfJ5Oc0vY9Bnyw/XtOace/ob3waGOSjPh9eXZ7CdIt7ftz6oT1q9r6m4ZflpTknKHv561JVrTv4/9q+7o9ySuOw386PUIZCpq1kvwYg0HQntcG8DsMPJXBQH2/C7wV+EBV3d42WQX8BvDjwFP43otb3gC8uKqeyWDsnNcOHebbVfX8qrpqkhLuq6rnAn8DXAm8HHgOg6EWSPISYEU77rnAs5KMDyC4Anh3VZ0DfBX4l1X14Xb8f91Gon0Q+K9V9ez2wqNTgJ8f4ftyIvCXwKvby5BeDDw4odtdwAuq6hnAGxkMWQLwq8A72/dzDNgDnA/sraqntzo+/nA1aO7y8pFms9XAs4Ab2h/QpwD7GfxSvgH4Ng8danl7VX0BIMmHGAzo921gJfB/2j5OZPBioXF/eZTjb2nT24DHVdXXga8n+XYGrzB9Sfu6qfV7HIMwuBe4p6pubu03AsumOMZPJ/lNBu+uWAjsBD56lJpgEIz7quoG6IadZsJJxg8Bm5KsAAoYH/DwOuA/JVkKfKSq7k5yG/D2JH8AfKyq/uZhjq85zFDQbBZgU1Vd9pDG5IkMfgE/msEbt8bftjVxIK9q+9haVa9kckd7U9fBNv3u0Pz48glt379fVe+ZUN+yCf0PMwg0JvQ7GbgCGKuq+zJ4L/ERw0JPIhz5b53od4C/rqp/0eq5FqCq/iLJ9cDPAZ9I8stV9akkzwJ+Fvj9JJ+sqreMUIfmIC8faTbbBrw8yRkASRYmeTKDF//8Z+CDwB8M9V+VZHm7l/AK4DPA3wLPS/IjbR+PSfJPj1N9nwB+aegexZLxWo/i6wzeagffC4Avt32M+mmju4AnJXl2O+6pGQwdPeyHgL9v868ab0zyw8AXquqPGZwJ/UT7NNS3quoDwNuBZ45Yh+YgzxQ0a1XVHRm8avGT7Rf9PwLXAIfaX7wLgM8meRGDv96vAy5ncE/h08DVVfXdJK8CPpTkpLbrNwD/9zjU98l23+O6dunmG8BFDM4MpnIl8CdJHgSeC/wpg8tTX2RwSWyU436n3Qx+V5JTGNxPmPhR2rcyuHz0WuBTQ+2vAC5K8o/Alxhcins2gyGov8vge/zvRqlDc5NDZ2tOSPJC4HVV9bA3aiVNzctHkqSOZwrSLJbkamD5hOb/WFWfmIl6NPcZCpKkjpePJEkdQ0GS1DEUJEkdQ0GS1Pn/Ah2tw+gak5EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# to see how many are RB class and how many are NRB class exist within this dataset\n",
    "import seaborn as sns\n",
    "sns.countplot(x='experimental_class', data=qsar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd441b8",
   "metadata": {},
   "source": [
    "### Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1687a982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing the str label into 1s and 0s\n",
    "qsar['experimental_class'] = qsar['experimental_class'].astype('category')\n",
    "encode_map = {\n",
    "    'RB':1,\n",
    "    'NRB':0\n",
    "}\n",
    "qsar['experimental_class'].replace(encode_map,inplace=True)\n",
    "# 1 reprsents RB and O represents NRB [changed it into a binary classification problem]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5be88ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qsar.isnull().values.any() # checking if there is any missing value in data frame\n",
    "qsar.isnull().sum().sum() # sums of missing value in the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dd83645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the target variable and the feature variable\n",
    "y = qsar['experimental_class']\n",
    "x = qsar.drop(columns='experimental_class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08b49a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_scaler = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49cbb2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(759, 41)\n",
      "(85, 41)\n",
      "(211, 41)\n"
     ]
    }
   ],
   "source": [
    "### Splitting the dataset before conducting SFS [forward and backward]\n",
    "seed_num = 80\n",
    "# creating set for SFS usage, the remaining set is for testing the model\n",
    "x_sfs,x_not_sfs, y_sfs, y_not_sfs = train_test_split(x_scaler, y, test_size=0.2,random_state=seed_num)\n",
    "\n",
    "# creating the validation set based on the training set \n",
    "x_sfs, x_valid, y_sfs, y_valid = train_test_split(x_sfs, y_sfs, test_size=0.1, random_state=seed_num)\n",
    "\n",
    "print(x_sfs.shape) # for sfs and training \n",
    "print(x_valid.shape) # for validation\n",
    "print(x_not_sfs.shape) # for testing\n",
    "\n",
    "# will be using x_sfs and y_sfs for SFS training and for training the model itself\n",
    "# the x_not_sfs and y_not_sfs is not used for the SFS training, it will be used for testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b98d4d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(759,)\n",
      "(85,)\n",
      "(211,)\n"
     ]
    }
   ],
   "source": [
    "print (y_sfs.shape) # for sfs and training\n",
    "print(y_valid.shape) # for validation\n",
    "print(y_not_sfs.shape) # for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "989ad702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# lasso is used for the feature selection process for backward and forward direction \n",
    "lasso = LassoCV().fit(x_sfs,y_sfs)\n",
    "#device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5c0dc6",
   "metadata": {},
   "source": [
    "### Feature selection\n",
    "The number of features to select is set manually by the user. The direction as well. It can be 'forward' or 'backward'\n",
    "The number of feature selected is done in increment of 5. But since it is a neural network, the starting number will be 20. So, the sequence would be 20,25,30,35 and 40."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbe82855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['SpMax_L', 'J_Dz(e)', 'nHM', 'F01[N-N]', 'F04[C-N]', 'nCb-', 'C%',\n",
      "       'nCp', 'nO', 'F03[C-N]', 'SdssC', 'HyWi_B(m)', 'LOC', 'SM6_L',\n",
      "       'F03[C-O]', 'Me', 'nN-N', 'nArNO2', 'nCRX3', 'nCIR', 'B01[C-Br]',\n",
      "       'B03[C-Cl]', 'N-073', 'SpMax_A', 'B04[C-Br]', 'SdO', 'TI2_L', 'nCrt',\n",
      "       'F02[C-N]', 'SpMax_B(m)', 'Psi_i_A', 'nN', 'SM6_B(m)', 'nArCOOR', 'nX'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# feature selection is done here.\n",
    "# the number of features to select and the direction must be set manually [35,backward]\n",
    "\n",
    "sfs = SequentialFeatureSelector(lasso, direction='backward',n_features_to_select=35, cv=5)\n",
    "x_after_sfs = sfs.fit_transform(x_sfs, y_sfs) # x_after_sfs holds the selected features \n",
    "selected_feature = x.columns [sfs.get_support(indices=True)]\n",
    "print(selected_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b73aac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on sfs\n",
    "# updating the test set, 'x_test_for' according to 'sfs' selection\n",
    "# assign 'x_not_sfs' to 'x_test_' --> to be used for testing later\n",
    "x_test_ = x_not_sfs \n",
    "x_test_ = sfs.transform(x_test_)\n",
    "\n",
    "# updating the validation set, 'x_val_' according to 'sfs' selection\n",
    "# assign 'x_valid' to 'x_val_for' --> to be used for validation later\n",
    "x_val_ = x_valid\n",
    "x_val_ = sfs.transform(x_val_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ce8583f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the target variables for later usage\n",
    "y_train = y_sfs\n",
    "y_test = y_not_sfs\n",
    "y_val = y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53cec6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing the training set, testing set and validation set into Tensors\n",
    "x_train_tensor = torch.tensor(x_after_sfs, dtype=torch.float, device=device,requires_grad=False) \n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float, device=device,requires_grad=False) \n",
    "\n",
    "x_val_tensor = torch.tensor(x_val_ , dtype=torch.float, device=device,requires_grad=False)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float, device=device,requires_grad=False)\n",
    "\n",
    "x_test_tensor = torch.tensor(x_test_ , dtype=torch.float, device=device,requires_grad=False)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float, device=device,requires_grad=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea83067",
   "metadata": {},
   "source": [
    "### CREATING THE NEURAL NETWORK MODEL BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2bfe656a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=35, out_features=15, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=15, out_features=7, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=7, out_features=1, bias=True)\n",
       "  (5): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the layers for the neural model is set and defined [4 layer with 2 hidden layers]\n",
    "neural_model = nn.Sequential(\n",
    "    nn.Linear(35,15),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(15,7),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(7,1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "neural_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1732cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (fc1): Linear(in_features=35, out_features=15, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (fc2): Linear(in_features=15, out_features=7, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (fc3): Linear(in_features=7, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using Sequential with OrderedDict\n",
    "neural_model = nn.Sequential(OrderedDict([\n",
    "    ('fc1', nn.Linear(35,15)),\n",
    "    ('relu1', nn.ReLU()),\n",
    "    ('fc2', nn.Linear(15,7)),\n",
    "    ('relu2',nn.ReLU()),\n",
    "    ('fc3', nn.Linear(7,1)),\n",
    "    ('sigmoid', nn.Sigmoid())\n",
    "]))\n",
    "neural_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55557de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the loss function is defined\n",
    "loss_function = nn.BCELoss() # this function is used since it is a binary classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "479a7988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (fc1): Linear(in_features=35, out_features=15, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (fc2): Linear(in_features=15, out_features=7, bias=True)\n",
      "  (relu2): ReLU()\n",
      "  (fc3): Linear(in_features=7, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# the optimizer for the neural model is defined\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.RMSprop(neural_model.parameters(), lr=learning_rate, alpha=0.9, eps=1e-07)\n",
    "print(neural_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91cf15e",
   "metadata": {},
   "source": [
    "### Training the neural model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a24583f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training of the model starts\n",
    "# the weights are not user defined\n",
    "neural_model.train()\n",
    "epochs = 500\n",
    "\n",
    "for e in range(0,epochs):\n",
    "    loss_train = 0\n",
    "    acc_train = 0\n",
    "    loss_val = 0\n",
    "    acc_val = 0\n",
    "    \n",
    "    # forward propagation with the training set\n",
    "    yhat_train = neural_model(x_train_tensor)\n",
    "    # the loss value is determined\n",
    "    loss = loss_function(yhat_train,y_train_tensor.reshape(-1,1))\n",
    "    # the gradient is set back to zero before performing backward propagation\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    # the weights are updated\n",
    "    optimizer.step()\n",
    "    \n",
    "    # the training loss value is obtained\n",
    "    loss_train = loss.item()\n",
    "    y_pred_train = torch.round(yhat_train)\n",
    "    acc_train = (y_pred_train.ravel() == y_train_tensor).type(torch.float).sum().item()\n",
    "    \n",
    "    #validation set\n",
    "    #the NN model predicts the validation set\n",
    "    yhat_val = neural_model(x_val_tensor)\n",
    "    loss = loss_function(yhat_val, y_val_tensor.reshape(-1,1))\n",
    "    # the validation loss value is obtained\n",
    "    loss_val = loss.item()\n",
    "    y_pred_val = torch.round(yhat_val) # the class is determined [0,1]\n",
    "    acc_val = (y_pred_val.ravel() == y_val_tensor).type(torch.float).sum().item()\n",
    "    \n",
    "    if e % 10 == 0:\n",
    "        acc_train = acc_train / len(x_train_tensor)\n",
    "        acc_val = acc_val / len(x_val_tensor)\n",
    "        #print(f'{e}, train_loss: {loss_train:.6f}, train_acc: {acc_train:.3f},val_loss: {loss_val:.6f}, val_acc: {acc_val:.3f}')\n",
    "  \n",
    "              "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a988544f",
   "metadata": {},
   "source": [
    "### Neural Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1fef2cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For training set\n",
      "Mean absolute error : 0.30566534\n",
      "Mean squared error : 0.30566534\n",
      "r2 score : -0.3727918638403367\n",
      "The max error value : 1.0\n",
      "\n",
      "(759, 1)\n",
      "accuracy score:  0.69433465085639\n",
      "[[505   0]\n",
      " [232  22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      1.00      0.81       505\n",
      "         1.0       1.00      0.09      0.16       254\n",
      "\n",
      "    accuracy                           0.69       759\n",
      "   macro avg       0.84      0.54      0.49       759\n",
      "weighted avg       0.79      0.69      0.59       759\n",
      "\n",
      "\n",
      "For testing set\n",
      "Mean absolute error : 0.30805686\n",
      "Mean squared error : 0.30805686\n",
      "r2 score : -0.3797786869704749\n",
      "The max error value : 1.0\n",
      "\n",
      "(211, 1)\n",
      "accuracy score:  0.6919431279620853\n",
      "[[138   2]\n",
      " [ 63   8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.99      0.81       140\n",
      "         1.0       0.80      0.11      0.20        71\n",
      "\n",
      "    accuracy                           0.69       211\n",
      "   macro avg       0.74      0.55      0.50       211\n",
      "weighted avg       0.72      0.69      0.60       211\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Printing out the results of the model. It is recorded in the report\n",
    "with torch.no_grad(): # ignoring the gradient\n",
    "    y_train_pred = neural_model(x_train_tensor)\n",
    "    y_pred = neural_model(x_test_tensor)\n",
    "\n",
    "print(\"For training set\")\n",
    "y_train_pred = y_train_pred.round().numpy()\n",
    "print(\"Mean absolute error : \" + str(mean_absolute_error(y_train_tensor, y_train_pred)))\n",
    "print(\"Mean squared error : \" + str(mean_squared_error(y_train_tensor, y_train_pred)))\n",
    "print(\"r2 score : \"+ str(r2_score(y_train_tensor, y_train_pred)))\n",
    "print(\"The max error value : \" + str(max_error(y_train_tensor, y_train_pred)) + \"\\n\")\n",
    "print(y_train_pred.shape)\n",
    "print(\"accuracy score: \", accuracy_score(y_train_tensor, y_train_pred))\n",
    "print(confusion_matrix(y_train_tensor, y_train_pred))\n",
    "print(classification_report(y_train_tensor, y_train_pred)) \n",
    "     \n",
    "print(\"\\nFor testing set\")  \n",
    "y_pred = y_pred.round().numpy()\n",
    "print(\"Mean absolute error : \" + str(mean_absolute_error(y_test_tensor, y_pred)))\n",
    "print(\"Mean squared error : \" + str(mean_squared_error(y_test_tensor, y_pred)))\n",
    "print(\"r2 score : \"+ str(r2_score(y_test_tensor, y_pred)))\n",
    "print(\"The max error value : \" + str(max_error(y_test_tensor, y_pred)) + \"\\n\")\n",
    "print(y_pred.shape)\n",
    "print(\"accuracy score: \", accuracy_score(y_test_tensor, y_pred))\n",
    "print(confusion_matrix(y_test_tensor, y_pred))\n",
    "print(classification_report(y_test_tensor, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1237d02",
   "metadata": {},
   "source": [
    "## Overall Best model from the Set of neural network model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd97085d",
   "metadata": {},
   "source": [
    "A best model is was picked from the set of neural network model that was created and evaluated. \n",
    "The best model that was picked is the neural network model with 35 features where the features \n",
    "are selected through backward SFS. The best model is loaded down below. The model name is 'best_neural_model'. \n",
    "In order to print out evaluation score, the entire notebook must be executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61a45145",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(neural_model.state_dict(), 'neural-model/best-neural-model35.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f0334302",
   "metadata": {},
   "outputs": [],
   "source": [
    "#neural_model.state_dict(torch.load('neural-model/best-neural-model35.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "efcb9d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(neural_model,'neural-model/best-neural-model35.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a8b30e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the best NN model\n",
    "best_neural_model = torch.load('neural-model/best-neural-model35.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "75d9c1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error : 0.15165877\n",
      "Mean squared error : 0.15165877\n",
      "r2 score : 0.3207243387222277\n",
      "The max error value : 1.0\n",
      "\n",
      "(211, 1)\n",
      "accuracy score:  0.8483412322274881\n",
      "[[124  16]\n",
      " [ 16  55]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.89      0.89       140\n",
      "         1.0       0.77      0.77      0.77        71\n",
      "\n",
      "    accuracy                           0.85       211\n",
      "   macro avg       0.83      0.83      0.83       211\n",
      "weighted avg       0.85      0.85      0.85       211\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluating its peformance, the overall notebook must be executed first in order to run this cell.\n",
    "with torch.no_grad(): # ignoring the gradient\n",
    "    y_pred = best_neural_model (x_test_tensor)\n",
    "\n",
    "y_pred = y_pred.round().numpy()\n",
    "print(\"Mean absolute error : \" + str(mean_absolute_error(y_test_tensor, y_pred)))\n",
    "print(\"Mean squared error : \" + str(mean_squared_error(y_test_tensor, y_pred)))\n",
    "print(\"r2 score : \"+ str(r2_score(y_test_tensor, y_pred)))\n",
    "print(\"The max error value : \" + str(max_error(y_test_tensor, y_pred)) + \"\\n\")\n",
    "print(y_pred.shape)\n",
    "print(\"accuracy score: \", accuracy_score(y_test_tensor, y_pred))\n",
    "print(confusion_matrix(y_test_tensor, y_pred))\n",
    "print(classification_report(y_test_tensor, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
